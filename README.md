# paper-notes
Because remembering things is hard.

## 2022
### June
- Policy Consolidation for Continual Reinforcement Learning [[paper](https://arxiv.org/pdf/1902.00255.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/Policy_Consolidation_for_Continual%20Reinforcement_Learning.md)]
- Towards Continual Reinforcement Learning: A Review and Perspectives [[paper](https://arxiv.org/pdf/2012.13490.pdf)]

### July
- Continual Backprop:
Stochastic Gradient Descent with Persistent Randomness [[paper](https://arxiv.org/pdf/2108.06325.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/continual_backprop.md)]
- Deep Reinforcement Learning with Double Q-learning [[paper](https://arxiv.org/pdf/1509.06461v3.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/double_dqn.md)]
- Implicit under-parameterization inhibits data-efficient deep reinforcement learning [[paper](https://arxiv.org/pdf/2010.14498.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/under_parameterization_deep_rl.md)]
- Towards Continual Reinforcement Learning: A Review and Perspectives [[paper](https://arxiv.org/pdf/2012.13490.pdf)][[slides](https://github.com/jordancoblin/paper-notes/blob/main/Continual%20Learning%20in%20RL.key)]

## TO ADD (already read)
- Memento paper
- Capacity loss paper

## TO READ
- Attention is all you need [[paper](https://arxiv.org/pdf/1706.03762.pdf)]
- Gato paper [[paper](https://arxiv.org/pdf/2205.06175.pdf)]
- BERT paper [[paper](https://arxiv.org/abs/1810.04805)]
