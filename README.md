# paper-notes
Because remembering things is hard.

## 2022
### June
- Policy Consolidation for Continual Reinforcement Learning [[paper](https://arxiv.org/pdf/1902.00255.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/Policy_Consolidation_for_Continual%20Reinforcement_Learning.md)]
- Towards Continual Reinforcement Learning: A Review and Perspectives [[paper](https://arxiv.org/pdf/2012.13490.pdf)]
- No More Pesky Hyperparameters: Offline Hyperparameter Tuning for RL [[paper](https://arxiv.org/abs/2205.08716)] [[notes](https://github.com/jordancoblin/paper-notes/blob/main/han_calib_model.md)]
- On Catastrophic Interference in Atari 2600 Games [[paper](https://arxiv.org/pdf/2002.12499.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/memento.md)]

### July
- Continual Backprop:
Stochastic Gradient Descent with Persistent Randomness [[paper](https://arxiv.org/pdf/2108.06325.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/continual_backprop.md)]
- Deep Reinforcement Learning with Double Q-learning [[paper](https://arxiv.org/pdf/1509.06461v3.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/double_dqn.md)]
- Implicit under-parameterization inhibits data-efficient deep reinforcement learning [[paper](https://arxiv.org/pdf/2010.14498.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/under_parameterization_deep_rl.md)]
- Towards Continual Reinforcement Learning: A Review and Perspectives [[paper](https://arxiv.org/pdf/2012.13490.pdf)][[slides](https://github.com/jordancoblin/paper-notes/blob/main/Continual%20Learning%20in%20RL.key)]

### August
- Attention is all you need [[paper](https://arxiv.org/pdf/1706.03762.pdf)]
- Mastering the game of Go with deep
neural networks and tree search (AlphaGo paper) [[paper](https://www.nature.com/articles/nature16961.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/alpha_go_1.md)]
- World Models [[paper](https://arxiv.org/pdf/1803.10122.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/world_models.md)]

### September
- The Phenomenon of Policy Churn [[paper](https://arxiv.org/pdf/2206.00730.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/policy_churn.md)]
- Reinforcement Learning with Unsupervised Auxiliary Tasks [[paper](https://arxiv.org/pdf/1611.05397.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/unsupervised_aux_tasks.md)]
- [Blog Post] Understanding Variational Autoencoders (VAEs) [[post](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/vaes_blog_post.md)]

### October
- Learning Latent Dynamics for Planning from Pixels [[paper](https://arxiv.org/pdf/1811.04551.pdf)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/planet_paper_review.pdf)]
- Auto-Encoding Variational Bayes [[paper](https://arxiv.org/pdf/1312.6114v10.pdf)]
- The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables [[paper](https://openreview.net/pdf?id=rkE3y85ee)][[notes](https://github.com/jordancoblin/paper-notes/blob/main/concrete_distr.md)]

## TO ADD (already read)
- Capacity loss paper

## TO READ
- Gato paper [[paper](https://arxiv.org/pdf/2205.06175.pdf)]
- BERT paper [[paper](https://arxiv.org/abs/1810.04805)]
- DALL-E paper [[paper](https://arxiv.org/pdf/2102.12092.pdf)]
- “Why Should I Trust You?” Explaining the Predictions of Any Classifier [[paper](https://arxiv.org/pdf/1602.04938.pdf)]
- Algos: TRPO, PPO, A3C
- TRPO paper [[paper](https://arxiv.org/abs/1502.05477)]
- [Learning to summarize from human feedback](https://arxiv.org/pdf/2009.01325.pdf)
- [Reinforcement Learning with Unsupervised Auxiliary Tasks](https://arxiv.org/abs/1611.05397) -> [Universal Value Function Approximators](http://proceedings.mlr.press/v37/schaul15.pdf) -> [Unicorn: Continual learning with a universal,
off-policy agent](https://arxiv.org/pdf/1802.08294.pdf)

Policy gradient progression:
- Blog post: https://sanyamkapoor.com/kb/policy-gradients-in-a-nutshell
- [Policy Gradient Methods for
Reinforcement Learning with Function
Approximation ](https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf) / [Simple statistical gradient-following algorithms for connectionist reinforcement learning](https://link.springer.com/article/10.1007/BF00992696) -> [Deterministic Policy Gradient Algorithms](http://proceedings.mlr.press/v32/silver14.pdf]) -> [DDPG](https://arxiv.org/pdf/1509.02971.pdf) -> [Distributed Distributional Deterministic Policy Gradients](https://arxiv.org/abs/1804.08617)
- [A3C (Asynchronous methods for deep reinforcement
learning)](https://arxiv.org/abs/1602.01783)

Good experimentation practices:
- [Deep Reinforcement Learning that Matters](https://arxiv.org/abs/1709.06560)
- [Evaluating the Performance of Reinforcement Learning Algorithms](https://arxiv.org/pdf/2006.16958.pdf)

RNN world models/event simulators:
- [Recurrent Environment Simulators](https://arxiv.org/abs/1704.02254)

Continual Learning in DRL/Performance Collapse/Dying ReLUs/etc:
- [Which Neural Net Architectures Give Rise To Exploding and Vanishing Gradients?](https://arxiv.org/abs/1801.03744) (2018)
- [Dying ReLU and Initialization: Theory and Numerical Examples](https://arxiv.org/abs/1903.06733) (2019)
- [A Convergence Analysis of Gradient Descent for Deep Linear Neural Networks](https://arxiv.org/abs/1810.02281)
- [Meta-Learning Representations for Continual Learning](https://arxiv.org/pdf/1905.12588.pdf) - Khurram's paper
- [Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference](https://arxiv.org/pdf/1810.11910.pdf) - MER paper
- [Experience Replay for Continual Learning](https://proceedings.neurips.cc/paper/2019/file/fa7cdfad1a5aaf8370ebeda47a1ff1c3-Paper.pdf)
- [Fixup Initialization: Residual Learning Without Normalization](https://arxiv.org/abs/1901.09321)
- [Continual Learning for Robotics](https://www.researchgate.net/profile/Natalia-Diaz-Rodriguez/publication/334161654_Continual_Learning_for_Robotics/links/5d80f16fa6fdcc12cb96f278/Continual-Learning-for-Robotics.pdf) (Recommended from Zaheer)
- [Continuous Meta-Learning without Tasks](https://arxiv.org/abs/1912.08866)

Memory:
- [Unsupervised Predictive Memory in a Goal-Directed Agent](https://arxiv.org/pdf/1803.10760.pdf%22)

DL:
- [Imagenet classification with deep convolutional neural networks](https://dl.acm.org/doi/pdf/10.1145/3065386)

MBRL:
- [World Models](https://arxiv.org/abs/1803.10122) -> [SimPLe](https://arxiv.org/abs/1903.00374) -> [PlaNet](https://arxiv.org/abs/1811.04551) -> [Dreamer](https://arxiv.org/abs/1912.01603)/[DreamerV2](https://arxiv.org/pdf/2010.02193.pdf)
- [A Game Theoretic Framework for Model Based Reinforcement Learning](https://arxiv.org/pdf/2004.07804.pdf)
- [Competitive Gradient Descent](https://arxiv.org/abs/1905.12103)
- [LEARNING AWARENESS MODELS](https://arxiv.org/pdf/1804.06318.pdf)
- [Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models](https://arxiv.org/abs/1805.12114)
- [When to Trust Your Model: Model-Based Policy Optimization](https://arxiv.org/pdf/1906.08253.pdf)

Real-world RL:
- [An empirical investigation of the challenges of
real-world reinforcement learning](https://arxiv.org/pdf/2003.11881.pdf)

Variatinal Inference:
- [Variational Inference: A Review for Statisticians](https://arxiv.org/pdf/1601.00670.pdf)

OpenAI Spinning up RL Key Papers:

https://spinningup.openai.com/en/latest/spinningup/keypapers.html
